{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APE: a cookbook\n",
    "\n",
    "This notebook is a playground for Anonymisation Pseudonymisation Encryption (APE) techniques\n",
    "\n",
    "The very basics on different techniques will be demonstrated and will rely on software provided in Python libraries. \n",
    "\n",
    "## TOC:\n",
    "* [The source file](#source-file)\n",
    "* [Removing a column](#removing-a-column)\n",
    "* [Tokenization](#tokenization)\n",
    "\n",
    "\n",
    "date: 2021-03\n",
    "\n",
    "inspiration: \n",
    "* https://korniichuk.medium.com/gdpr-guide-2-7c399b44ba3#adce\n",
    "* https://developer.ibm.com/solutions/security/articles/s-gdpr3/\n",
    "* https://www.anonos.com/enisa-chapter-1-introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The source file<a class=\"anchor\" id=\"source-file\"></a>\n",
    "\n",
    "A csv-file (ape_0.csv) is taken as a starting point. The mock data contained in this file are created from https://www.mockaroo.com/\n",
    "\n",
    "This file contains the columns:\n",
    "* id\t\n",
    "* first_name\t\n",
    "* last_name\t\n",
    "* email\t\n",
    "* gender\t\n",
    "* ip_address\t\n",
    "* city\t\n",
    "* country\t\n",
    "* age\n",
    "* income\n",
    "* score_1\t\n",
    "* score_2\n",
    "\n",
    "The data is imported as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "working_source = 'https://raw.githubusercontent.com/franklbvp/didactic-dollop/main/ape/ape_0.csv'\n",
    "\n",
    "# reading CSV input\n",
    "df = pd.read_csv(working_source)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing a column<a class=\"anchor\" id=\"removing-a-column\"></a>\n",
    "\n",
    "If data is not necessary for the research purpose, just remove it. Keep on the minimal data rule!\n",
    "\n",
    "drop the unnecessary column(s). In this example the column `email` will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"email\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving a dataframe\n",
    "\n",
    "* The dataframe containing only the necessary information can be saved back into a .csv file.  \n",
    "* Delete the original file and continue with the file containing the minimal info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ape_0_drop.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization<a class=\"anchor\" id=\"tokenization\"></a>\n",
    "\n",
    "A token is a pseudonym, and this pseudonym is being used instead of the original data.\n",
    "\n",
    "The `uuid` library is used in this case. Universal Unique Identifier, is a python library which helps in generating random objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "def email_tokenization(email):\n",
    "    if email not in key:\n",
    "        token = uuid.uuid4()\n",
    "        while token in key.values():  # the token must be unique\n",
    "            token = uuid.uuid4()\n",
    "        key[email] = token\n",
    "        return token\n",
    "    else:\n",
    "        return key[email]\n",
    "\n",
    "# reading CSV input\n",
    "df = pd.read_csv(working_source)\n",
    "\n",
    "key = {}\n",
    "df.email = df.email.map(email_tokenization)  # original email address is overwritten\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ape_0_token.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code can be tweaked a little to create a lookup table.\n",
    "This lookup table will enable returning back to the original data. Keep this lookup table safe and separately stored from the tokenized data.\n",
    "\n",
    "The original data are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# reading CSV input\n",
    "df = pd.read_csv(working_source)\n",
    "\n",
    "def email_tokenization(email):\n",
    "    if email not in key:\n",
    "        token = uuid.uuid4()\n",
    "        while token in key.values():  # the token must be unique\n",
    "            token = uuid.uuid4()\n",
    "        key[email] = token\n",
    "        return token\n",
    "    else:\n",
    "        return key[email]\n",
    "\n",
    "\n",
    "\n",
    "key = {}\n",
    "df['emailT'] = df.email.map(email_tokenization)  # a new column is created with the tokens\n",
    "\n",
    "# create the lookup table and save it\n",
    "df_lookup = df[['email', 'emailT']]\n",
    "df_lookup.to_csv('lookup_0_email_token.csv') \n",
    "\n",
    "# remove the original email column\n",
    "df.drop(columns=['email'], inplace=True)\n",
    "\n",
    "df_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization\n",
    "\n",
    "A simple example on generalizing numerical data. The values are checked and a string is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def age_generalization(age):\n",
    "    if age < 18:\n",
    "        return 'Age <= 18'\n",
    "    else:\n",
    "        return 'Age > 18'\n",
    "    \n",
    "def income_generalization(income):\n",
    "    if income < 24000:\n",
    "        return 'Below Average'\n",
    "    else:\n",
    "        return 'Above Average'\n",
    "\n",
    "# reading CSV input\n",
    "df = pd.read_csv(working_source)\n",
    "\n",
    "\n",
    "df.age = df.age.map(age_generalization)\n",
    "df.income = df.income.map(income_generalization)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "def email_pseudonymization(email):\n",
    "    if email not in key:\n",
    "        pseudonym = fake.email()\n",
    "        while (pseudonym in key.values()) or (pseudonym in key):\n",
    "            pseudonym = fake.email()\n",
    "        key[email] = pseudonym\n",
    "        return pseudonym\n",
    "    else:\n",
    "        return key[email]\n",
    "\n",
    "# reading CSV input\n",
    "df = pd.read_csv(working_source)\n",
    "\n",
    "key = {}\n",
    "fake = Faker()\n",
    "df.email = df.email.map(email_pseudonymization)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "def email_hashing(email):\n",
    "    if email not in key:\n",
    "        sha3 = hashlib.sha3_512()\n",
    "        data = salt + email\n",
    "        sha3.update(data.encode('utf-8'))\n",
    "        hexdigest = sha3.hexdigest()\n",
    "        key[email] = hexdigest\n",
    "        return hexdigest\n",
    "    else:\n",
    "        return key[email]\n",
    "\n",
    "# reading CSV input\n",
    "df = pd.read_csv(working_source)\n",
    "\n",
    "salt = 'medium'\n",
    "key = {}\n",
    "df.email = df.email.map(email_hashing)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encryption\n",
    "\n",
    "source: https://www.geeksforgeeks.org/encrypt-and-decrypt-files-using-python/\n",
    "\n",
    "The `cryptography` library will be used to encrypt a file. The cryptography library uses a symmetric algorithm to encrypt the file. In a symmetric algorithm, the same key is used to encrypt and decrypt the file. The fernet module of the cryptography package has inbuilt functions for the generation of the key, encryption of plain text into cipher text, and decryption of cipher text into plain text using the `encrypt()` and `decrypt()` methods respectively. The fernet module guarantees that data encrypted using it cannot be further manipulated or read without the key. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a key\n",
    "a key is used to encrypt text, in order to have a strong key, it can be generated by the software library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required module \n",
    "from cryptography.fernet import Fernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key generation \n",
    "key = Fernet.generate_key() \n",
    "  \n",
    "# string the key in a file \n",
    "with open('filekey.key', 'wb') as filekey: \n",
    "   filekey.write(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypting a string\n",
    "\n",
    "The methods work with bytes, this requires encoding and decoding the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"My secret message\".encode() # bytes\n",
    "# initialize the Fernet class\n",
    "f = Fernet(key)\n",
    "# encrypt the message\n",
    "encrypted = f.encrypt(message)\n",
    "# print how it looks\n",
    "print(encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted_encrypted = f.decrypt(encrypted)\n",
    "print(decrypted_encrypted)\n",
    "original_message = decrypted_encrypted.decode() # bytes to string\n",
    "print(original_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypting a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encrypt the file using the key generated\n",
    "\n",
    "* Open the file that contains the key.\n",
    "* Initialize the Fernet object and store it in the fernet variable.\n",
    "* Read the original file.\n",
    "* Encrypt the file and store it into an object.\n",
    "* Then write the encrypted data into the same file nba.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the key \n",
    "with open('filekey.key', 'rb') as filekey: \n",
    "    key = filekey.read() \n",
    "  \n",
    "# using the generated key \n",
    "fernet = Fernet(key) \n",
    "  \n",
    "# opening the original file to encrypt \n",
    "with open('ape_0.csv', 'rb') as file: \n",
    "    original = file.read() \n",
    "      \n",
    "# encrypting the file \n",
    "encrypted = fernet.encrypt(original) \n",
    "  \n",
    "# opening the file in write mode and  \n",
    "# writing the encrypted data \n",
    "with open('ape_0_encrypted.csv', 'wb') as encrypted_file: \n",
    "    encrypted_file.write(encrypted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypting an encrypted file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the key \n",
    "fernet = Fernet(key) \n",
    "  \n",
    "# opening the encrypted file \n",
    "with open('ape_0_encrypted.csv', 'rb') as enc_file: \n",
    "    encrypted = enc_file.read() \n",
    "  \n",
    "# decrypting the file \n",
    "decrypted = fernet.decrypt(encrypted) \n",
    "  \n",
    "# opening the file in write mode and \n",
    "# writing the decrypted data \n",
    "with open('ape_0_decrypt.csv', 'wb') as dec_file: \n",
    "    dec_file.write(decrypted) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
